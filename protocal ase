##################################
##################  */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase*
### 00.trimmed and filtered */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/00.cleaned.data*
while read i ; do fastp -i $i'_1.fq.gz' -I $i'_2.fq.gz' -o $i'cleaned_1.fq.gz' -O $i'cleaned_2.fq.gz' -l 36 -q 20 -w 12 ; done < list
### 01.reads_mapping */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/02.star*
STAR v2.7.9a was used with default parameters for the read mapping on the C.gigas reference genome with GTF file, by the Multi-sample 2-pass method.
1. Run 1st mapping pass for all samples with ”usual” parameters. Using annotations is recommended either a the genome generation step, or mapping step.
2. Run 2nd mapping pass for all samples , listing SJ.out.tab files from all samples in
--sjdbFileChrStartEnd /path/to/sj1.tab /path/to/sj2.tab ....
# 01./1/ star 1-pass index
STAR --runMode genomeGenerate --runThreadN 8 --genomeDir 01.star_index/ \
--genomeFastaFiles $gigas_ref.fa --sjdbGTFfile $gigas_ref.gtf --sjdbOverhang 149
# 01./2/ 1-pass mapping with indexed genome
while read i ; do STAR --genomeDir ../../05.ase2group/HPA_index/ --runThreadN 30  --readFilesIn $i'_1.cleaned.fq.gz'  $i'_2.cleaned.fq.gz'  --readFilesCommand zcat --outSAMunmapped Within --outFileNamePrefix '02.1-pass/'$i  > '02.1-pass/log2map.'$i 2>&1  ; done < list
cat *.tab | awk '($5 > 0 && $7 > 2 && $6==0)' | cut -f1-6 | sort | uniq > SJ.filtered.tab
# 2-pass mapping with SJ.out.tab files
while read i ;
do STAR --genomeDir ../../05.ase2group/HPA_index/ \
--runThreadN 30 --sjdbFileChrStartEnd SJ.filtered.tab --readFilesCommand zcat \
--readFilesIn $i'_1.cleaned.fq.gz' $i'_2.cleaned.fq.gz' \
--outSAMmapqUnique 255 \
--outSAMtype BAM SortedByCoordinate --outBAMsortingThreadN 30 \
--outFileNamePrefix '03.2-pass/'$i \ > '03.2-pass/log2map.'$i 2>&1 ; done < list

while read i ; do samtools index $i'Aligned.sortedByCoord.out.bam' ; done < list
while read i ; do samtools view -@ 10 -b -h -f 2 -q 255 $i'Aligned.sortedByCoord.out.bam' > '../04.gatk/'$i'.uniq.bam' ;done < list

##### 02.GATK */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/03.gatk*
### 02.add_RG
while read i; do  gatk AddOrReplaceReadGroups --INPUT $i'.uniq.bam'  --OUTPUT '01.rg/'$i'.RG.bam' --RGID $i --RGPL ILLUMINA --RGLB $i --RGPU RG --RGSM $i --CREATE_INDEX true; done < list1
### 03.dedup_bam mark duplicates & index
while read i ; do gatk --java-options "-XX:ParallelGCThreads=20" MarkDuplicates \
-CREATE_INDEX true -VALIDATION_STRINGENCY SILENT --READ_NAME_REGEX null \
-I '01.rg/'$i'.RG.bam' -M '02.MarkDuplicates/'$i'.markdup_metrics.txt' -O '02.MarkDuplicates/'$i'.RG.markdup.bam'; done < list0
### 04.SplitNCigarReads [已删除过程文件，bam]
while read i ; do gatk --java-options "-XX:ParallelGCThreads=20" SplitNCigarReads --R /public1/node3_liushk/RarData_xb/04.ref/csi.main.fasta \
--I '02.MarkDuplicates/'$i'.RG.markdup.bam' --O '03.SplitNCigarReads/'$i'.RG.markdup.split.bam' ; done < list4

[报错信息]：
ERROR MESSAGE: Bad input:We encountered a non-standard non-IUPAC base in the provided reference: '10'，
问题可能是参考基因组序列文件编码格式有问题;在linux上用cat命令输出参考基因组序列文件，并重定向到新的文件。
cat Donkey_Hic_genome.20180408.fa > Donkey_Hic_genome.20180408.fa.bak
mv Donkey_Hic_genome.20180408.fa.bak Donkey_Hic_genome.20180408.fa
https://www.omicsclass.com/article/835

# 变异检测 HaplotypeCaller
HaplotypeCaller应用的参考置信模型，以生成每个样本的GVCF，由-ERC GVCF或调用-ERC BP_RESOLUTION
HaplotypeCaller 的工作原理是组装读取以创建潜在的单倍型，将读取重新排列为它们最可能的单倍型，然后通过它们的单倍型将这些读取投影回参考序列，以计算读取与参考的比对。在这一点上，我们可以计算每个可能的基因型的可能性并发出变异调用。
1 将完成比对的bam文件，通过对比所有带有 REF 碱基的读数与带有任何非参考碱基的所有读数，估计该位点不存在 SNP 的置信度。
2 通过计算提供反对这种插入缺失的证据的读数数量，估计在该位点不存在大小为 X（由命令行参数确定）的插入缺失的置信度，并根据该值估算我们不会看到等位基因的可能性信心十足地。
基于此，我们得到基因型似然 (PL) 并计算GQ（从PLs）这两个模型的最低置信度。我们使用象征性的 ALT 等位基因，NON_REF来保存该位点不是纯合参考的可能性，以及等位基因特异性AD和PL字段值。
# https://gatk.broadinstitute.org/hc/en-us/articles/360035531192-RNAseq-short-variant-discovery-SNPs-Indels-
# https://github.com/gatk-workflows/gatk3-4-rnaseq-germline-snps-indels/blob/master/rna-germline-variant-calling.wdl
# -stand-call-conf 20 -dont-use-soft-clipped-bases

REF=/public1/node3_liushk/RarData_xb/04.ref/csi.main.fasta
sample=( HiC_scaffold_1 HiC_scaffold_4 HiC_scaffold_6 HiC_scaffold_7 HiC_scaffold_9 HiC_scaffold_11 HiC_scaffold_14 HiC_scaffold_15 HiC_scaffold_17 HiC_scaffold_19 )
for i in ${sample[@]};do
gatk --java-options "-Xmx800m -Djava.io.tmpdir=./tmp" HaplotypeCaller  \
-R $REF -stand-call-conf 20 -dont-use-soft-clipped-bases \
-I 03.SplitNCigarReads/TA2.RG.markdup.split.bam \
-L $i  \
-O 04.split.gvcf/TA2.${i}.g.vcf.gz \
-ERC GVCF &
done && wait

**gatk MergeVcfs  -I TM2.HiC_scaffold_1.g.vcf.gz -I TM2.HiC_scaffold_4.g.vcf.gz -I TM2.HiC_scaffold_6.g.vcf.gz -I TM2.HiC_scaffold_7.g.vcf.gz -I TM2.HiC_scaffold_9.g.vcf.gz -I TM2.HiC_scaffold_11.g.vcf.gz -I TM2.HiC_scaffold_14.g.vcf.gz  -I TM2.HiC_scaffold_15.g.vcf.gz -I TM2.HiC_scaffold_17.g.vcf.gz -I TM2.HiC_scaffold_19.g.vcf.gz -O ../05.merge.gvcf/TM2.merge.g.vcf.gz**
**gatk --java-options "-Xmx12g"  CombineGVCFs  -R /public1/node3_liushk/RarData_xb/04.ref/csi.main.fasta --variant TA5.merge.g.vcf.gz --variant TD5.merge.g.vcf.gz --variant TG5.merge.g.vcf.gz --variant TL5.merge.g.vcf.gz --variant TM5.merge.g.vcf.gz -O ../06.ind.gvcf/T2.g.vcf.gz**
**gatk --java-options "-Xmx12g"  GenotypeGVCFs  -R /public1/node3_liushk/RarData_xb/04.ref/csi.main.fasta --variant T1.g.vcf.gz  -O T1.vcf.gz**

# SelectVariants (filter SNP) SNP 且仅为双等位基因   
gatk SelectVariants -select-type SNP  --restrict-alleles-to BIALLELIC -V T1.vcf.gz -O T1.snp.vcf.gz

## hard-filter SNPs  硬过滤
##### as recommended in https://github.com/broadgsa/gatk/blob/master/doc_archive/methods/Calling_variants_in_RNAseq.md
##### https://www.frontiersin.org/articles/10.3389/fgene.2021.655707/full
**FS and QD criteria**  **allele frequency**
## 不使用 --window 35 --cluster 3
nohup gatk VariantFiltration --filter-name "FS"  --filter "FS > 30.0" --filter-name "QD"  --filter "QD < 2.0"  -V T1.snp.vcf.gz -O T1.snps_fld.vcf.gz &
nohup gatk SelectVariants --exclude-filtered TRUE -V T1.snps_fld.vcf.gz -O T1.snps_fld_sel.vcf.gz &

#### data to FastaAlternateReferenceMaker */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/03.gatk/07.snp.result/01.snp2mask*
## 基因型过滤  GT with at least 10 reads >= 20%  && GT >= 50% （AN > 4  || AN >= 5）
zcat T1.snps_fld_sel.vcf.gz | SnpSift filter "( GEN[*].DP >= 10 )" > T1.snps.vcf
gatk SelectVariants --exclude-filtered TRUE -select "AN > 4" -V T1.snps.vcf -O T3.snps_fld_sel_2.vcf.gz
gatk SelectVariants -select "AF<1.00" --exclude-filtered TRUE -V T3.snps_fld_sel_2.vcf.gz  -O T3.snp2mask.vcf.gz

### biallelic SNPs
## T1 841,265 / 765,195
## T2 849,020 / 764,097
## T3 806,211 / 722,090

#### snp to allele identified */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/03.gatk/07.snp.result/00.data*
## High-quality heterozygous SNPs are defined as those showing the same genotype in at least two tissue types,
## and if the hetSNP is only identified in one tissue, they are retained upon validation by DNA sequencing data
bcftools query -f '%CHROM\t%POS\t%ID\t%REF\t%ALT[\t%GT\t%DP]\n' T3.snps_fld_sel.vcf.gz > T3.output.txt
awk -v OFS='\t' '{for (i=7; i<=NF; i+=2) {if ($i < 20) $(i-1)="./."}}1' T3.output.txt > tmp
awk -v OFS='\t' '{for (i=6; i<=NF; i+=2) {if ($(i) == "0/1" || $(i) == "0|1") {print $0; break}}}' tmp > tmp1
awk  -v OFS='\t' '{count=0; for (i=6; i<=NF; i+=2) {count += gsub(/0\/1|0\|1/, "", $i)}; print $0"\t"count}' tmp1 > tmp2

awk -F "\t" '{if($16>1) print $0}' tmp2 | awk '{print $1"\t"$2}' > tmp3
awk -F "\t" '{if($16<2) print $0}' tmp2 | cut -f 1-5 > tmp4

nohup gatk SelectVariants -V /public1/node3_liushk/RarData_xb/08.vcf/01.ind.snp/ndm6.filtered.snp.vcf.gz -select "AF < 1.00 " --exclude-filtered TRUE -O ndm6.het.filtered.snp.vcf.gz &
zcat ndm6.het.filtered.snp.vcf.gz | grep -v "#" | cut -f 1-5 > ndm6.het.vcf
grep -Ff tmp4 -w ndm6.het.vcf | awk '{print $1"\t"$2}' > tmp4.site
cat tmp4.site tmp3 | sort -k 1,1 -k 2,2n > sites_to_keep.t2.txt

vcftools --gzvcf T3.snps_fld_sel.vcf.gz --positions sites_to_keep.t3.txt --recode --out T3.snp2ase

**The result were then move to /public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/06.het.snp**

## 制作个体基因组  */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/03.gatk/08.ind.genome*
## bedtools getfasta -fi gigas.cc.fa -bed ../09.maskgenome/cc.snps_fld_sel_2.vcf.gz  -fo test.fa.out  ## 查看是否替换成功
nohup gatk FastaAlternateReferenceMaker -R /public1/node3_shicy/PRJ02_Csikamea/05.ase2group/HAP1.fasta --line-width 80 \
-V 07.snp.result/01.snp2mask/T1.snps_fld_sel_2.vcf.gz \
--snp-mask 07.snp.result/01.snp2mask/T1.snp2mask.vcf.gz --snp-mask-priority -O 08.ind.genome/T1.genome.fa &

awk -F "[ :]" '{if($1~">")print ">"$2 ; else print$0}' T1.genome.fa > tmp && mv tmp T1.genome.fa
gatk CreateSequenceDictionary -R T1.genome.fa -O T1.genome.dict
samtools faidx T1.genome.fa

## 比对至个体基因组 */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/04.STAR*
agat_convert_sp_gff2gtf.pl --gff /public1/node3_liushk/braker_result/03.braker_result/CskiameaA.longest.gff -o CskiameaA.gtf
nohup STAR --runMode genomeGenerate --runThreadN 20  --genomeDir 01.index/index_T1 --genomeFastaFiles ../04.gatk/08.ind.genome/T1.genome.fa --sjdbGTFfile ../CskiameaA.gtf --sjdbOverhang 149 &

while read i ; do STAR --genomeDir 01.index/index_T1 --runThreadN 20 --readFilesIn '../../00.cleaned.data/'$i'_1.cleaned.fq.gz'  '../../00.cleaned.data/'$i'_2.cleaned.fq.gz'  --readFilesCommand zcat --outSAMunmapped Within --outFileNamePrefix '02.1-pass/'$i  > '02.1-pass/log2map.'$i 2>&1  ; done < list1

cat T1*.tab | awk '($5 > 0 && $7 > 2 && $6==0)' | cut -f1-6 | sort | uniq > SJ.T1.filtered.tab

STAR --genomeDir ../01.index/index_T2 --sjdbFileChrStartEnd SJ.T2.filtered.tab --runThreadN 20 \
--readFilesIn ../../../00.cleaned.data/TM5_1.cleaned.fq.gz ../../../00.cleaned.data/TM5_2.cleaned.fq.gz \
--readFilesCommand zcat --outSAMmapqUnique 255 --outSAMtype BAM SortedByCoordinate --outBAMsortingThreadN 30 --outFileNamePrefix TM5 &

### 处理 bam */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/05.bam2phaser*
while read i ; do samtools index $i'Aligned.sortedByCoord.out.bam' ; done < list
while read i ; do samtools view -@ 10 -b -h -f 2 -q 255 $i'Aligned.sortedByCoord.out.bam' > '../../06.gatk/'$i'.uniq.bam' ;done < list

# MarkDuplicates
while read i ; do gatk --java-options "-XX:ParallelGCThreads=20" MarkDuplicates \
-CREATE_INDEX true -VALIDATION_STRINGENCY SILENT --READ_NAME_REGEX null \
-I '01.rg/'$i'.RG.bam' -M '02.MarkDuplicates/'$i'.markdup_metrics.txt' -O '02.MarkDuplicates/'$i'.RG.markdup.bam'; done < list0

# SplitNCigar
gatk --java-options "-XX:ParallelGCThreads=10" SplitNCigarReads --R ../09.maskgenome/gigas.cc.fa --I 05.pickup/cc1_pk.sorted.bam  --O 06.SplitNCigar/cc1.markdup.pk.split.bam > 06.SplitNCigar/log2split.cc1 2>&1 &

## 制作 het-snp data */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/06.het.snp*
## 杂合位点用于 等位基因检测
/public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/02.star/07.het.snp
awk '{if(!/^#/) print $1"\t"$2"\t"$3"\t"$5"\t"$4"\t"$6"\t"$7"\t"$8"\t"$9"\t"$10}' T1.snp2ase.recode.vcf > T1.info.snp
grep "#" T1.snp2ase.recode.vcf > head.T1.list
cat  head.T1.list T1.info.snp | cut -f 1-10 > T1.info.snp.vcf

cp /public1/node3_shicy/PRJ01_Cgigas/seq_rna/output/05.map2mask/snp_site/manipulate_vcf.pl .
./manipulate_vcf.pl -i T1.info.snp.vcf -o T1.info.snp.het.vcf
bcftools view -O z T1.info.snp.het.vcf > T1.info.snp.het.vcf.gz
bcftools index -t T1.info.snp.het.vcf.gz

zcat T1.info.snp.het.vcf.gz | grep -v "#" | wc -l

awk '($3=="exon") {OFS="\t"; print $1,$4-1,$5}' /public1/node3_liushk/braker_result/03.braker_result/CskiameaA.longest.gff > CskiameaA_gff_exon.bed
vcftools --gzvcf T3.info.snp.het.vcf.gz --bed CskiameaA_gff_exon.bed --recode --out T3.het.snp.exon

bcftools view -O z T1.het.snp.exon.recode.vcf > T1.het.exon.vcf.gz
bcftools index -t T1.het.exon.vcf.gz

@@@@@
awk '($3=="exon") {OFS="\t"; print $1,$4-1,$5,$9}' /public1/node3_liushk/braker_result/03.braker_result/CskiameaA.longest.gff > CskiameaA_gff_exon.bed
bedtools intersect -a CskiameaA_gff_exon.bed -b T1.info.snp.het.vcf.gz > intersected_output.t1.vcf
cut -d ";" -f 2 intersected_output.t1.vcf |  sort | uniq | wc -l



@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
allele identified using phaser
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
*/public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/07.phaser*

## TA1,TA2,TA3 For phase
awk '$3=="gene"'  /public1/node3_liushk/braker_result/03.braker_result/CskiameaA.longest.gff  | cut -f1,4,5,9 | awk -F $'\t' 'BEGIN {OFS = FS} {split($4, a, ";"); split(a[1], b, "="); print $1, $2-1, $3, b[2]}' > 01.csiA.gene.bed

cut -f 1 01.csiA.gene.bed | sort | uniq > 01.list
while read i ; do awk '{if($1=="'$i'")print $0}' 01.csiA.gene.bed > '02.'$i'.bed' ; done < 01.list

while read i ; do python /public/home/shicy/phaser/phaser/phaser.py --vcf T2.het.exon.vcf.gz --bam TA5.mk.split.bam,TD5.mk.split.bam,TG5.mk.split.bam,TL5.mk.split.bam,TM5.mk.split.bam  --paired_end 1 --mapq 60 --baseq 10 --sample TA5 --chr $i --threads 2  --id_separator - --o '02.phase/T3_'$i ; done < 01.bed/01.list

while read i; do python ~/phaser/phaser_gene_ae/phaser_gene_ae.py --haplotypic_counts 'T1_'$i'.haplotypic_counts.txt' --features '01.bed/02.'$i'.bed' --id_separator - --o '../09.phase_gene/T1_'$i'.gene_ae.txt'; done < 01.bed/list

#### compare the SNP with gene
cat T1_HiC_scaffold_* > T1.tmp
grep TD2.mk.split 00.data/T1.tmp > TD1.tmp.txt && cat T1.head TD1.tmp.txt > T1.TD.filted.txt
grep TM2.mk.split 00.data/T1.tmp > TM1.tmp.txt && cat T1.head TM1.tmp.txt > T1.TM.filted.txt
grep TL2.mk.split 00.data/T1.tmp > TL1.tmp.txt && cat T1.head TL1.tmp.txt > T1.TL.filted.txt
grep TG2.mk.split 00.data/T1.tmp > TL1.tmp.txt && cat T1.head TL1.tmp.txt > T1.TG.filted.txt
grep TA2.mk.split 00.data/T1.tmp > TA1.tmp.txt && cat T1.head TA1.tmp.txt > T1.TA.filted.txt

**Result in /public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase/08.phaser_result**

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
### 等位基因不平衡表达测试 在R中
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

######### bais /public1/node3_shicy/PRJ02_Csikamea/09.ASE/05.new.ase/03.bam
#### https://elifesciences.org/articles/72825
######### ASE gene
### (sample$aCount>10 | sample$bCount>10) & sample$n_variants>2, binom_q<0.05
######### AE gene
### (sample$aCount>10 | sample$bCount>10) & sample$n_variants>2, binom_q>0.1

library(ggplot2)
read.table('T1.TA.filted.txt',sep = "\t",header = 1) -> sample
cov10 = subset(sample, (sample$aCount>10 | sample$bCount>10) & sample$n_variants>2 )
cov10$ase <- (log2(cov10$aCount+1)-log2(cov10$bCount+1))
cov10$binom_p <- apply(cov10[,c("aCount","bCount")], 1, function(x) binom.test(x[1],x[1]+x[2],p=0.5)$p.value)
cov10$binom_q <- p.adjust(cov10$binom_p, method = "fdr")
dense = data.frame(density(cov10$ase)[c('x','y')])

T1.TA_ASE <- cov10[cov10$binom_q<0.05,]
T1.TA_mark_gene<-cov10[,c(1:4)]
T1.TA_AE <- cov10[cov10$binom_q>0.1,c(1:4)]

P <- ggplot(cov10,aes(x =cov10$ase))+
    geom_histogram(aes(y=after_stat(density)), color="#3e403f", alpha=.1, fill="#fffbf0", binwidth = .12, center=1)+
    geom_density()+
    geom_area(data = subset(dense,x >= 1 & x < 10), aes(x, y, fill = "Label 1"), alpha=.5)+
    geom_area(data = subset(dense,x >= -10 & x < -1), aes(x, y, fill = "Label 2"), alpha=.5)+
    geom_area(data = subset(dense,x  >= -1 & x < 1), aes(x, y, fill = "Label 3"), alpha=.5)+
    scale_fill_manual("Label title",
                      breaks = c("Label 1", "Label 2", "Label 3"),
                      values = c("Label 1"="#de1300", "Label 2"="#027bc2", "Label 3"="#f2f2f2"))+
    labs(x = 'log2(aCount+1)-log2(bCount+1)')+
    theme_bw()+ theme(legend.title=element_blank(),legend.position = "none") +
    theme(axis.text = element_text(size=12),
          axis.title = element_text(size=14, face="bold"))

pdf("01.bais_T1A.pdf.pdf",width=6, height=3)
P
dev.off()

write.csv(T1.TA_mark_gene,'02.T1.TA_mark_gene.csv',row.names = F)
write.csv(T1.TA_AE,'03.T1.TA_AE.csv',row.names = F)
write.csv(T1.TA_ASE,'04.T1.TA_ASE.csv',row.names = F)



####################################################################################################################
#### Then the result mv in */public1/node3_shicy/PRJ02_Csikamea/09.ASE/02.sample.ase_result*

ls 02.T* | cut -f 1 -d "_"  | sed 's/02.//g'  > 00.list
while read i; do cut -f 4 -d "," '02.'$i'_mark_gene.csv' | grep CsiA | sed 's/"//g' | sed 's/\r//g' | sort | uniq > '02.'$i'_mk_genelist' ; done < 00.list
while read i; do cut -f 4 -d "," '04.'$i'_ASE.csv' | grep CsiA | sed 's/"//g' | sed 's/\r//g' | sort | uniq > '04.'$i'_ase_genelist' ; done < 00.list
while read i; do cut -f 4 -d "," '03.'$i'_AE.csv' | grep CsiA | sed 's/"//g' | sed 's/\r//g' | sort | uniq > '03.'$i'_ae_genelist' ; done < 00.list

#### state in Supplementary Table S6
cat 04.T1*_ase_genelist  | sort | uniq -c | awk '{if($1>4) print $2}' | awk '{print $0"\t""con"}' > 01.t1.con
cat 04.T1*_ase_genelist  | sort | uniq -c | awk '{if($1<2) print $2}' | awk '{print $0"\t""sp"}' > 01.t1.sp
cat 04.T1*_ase_genelist  | sort | uniq -c | awk '{if($1<5 && $1 >1 ) print $2}' | awk '{print $0"\t""otherase"}' > 01.t1.other

cat 02.T1.T*mk_genelist  | sort | uniq > 01.t1.all.mk
cat 03.T1.T*_ae_genelist  | sort | uniq > 01.t1.all.ae
cat 04.T1.T*ase_genelist | sort | uniq > 01.t1.all.ase

grep -vFf 01.t2.all.ase -w  01.t2.all.ae | awk '{print $0"\t""ae"}' > 01.t2.ae

cat 01.t1.other 01.t1.con 01.t1.sp 01.t1.ae > ../t1.fin.tab
