
##################################
### 00.trimmed and filtered RNA-seq data
while read i ; do fastp -i $i'_1.fq.gz' -I $i'_2.fq.gz' -o $i'cleaned_1.fq.gz' -O $i'cleaned_2.fq.gz' -l 36 -q 20 -w 12 ; done < list

### 01.reads_mapping
# STAR v2.7.9a was used with default parameters for the read mapping on the C.gigas reference genome with GTF file, by the Multi-sample 2-pass method.
# 1. Run 1st mapping pass for all samples with ”usual” parameters. Using annotations is recommended either a the genome generation step, or mapping step.
# 2. Run 2nd mapping pass for all samples , listing SJ.out.tab files from all samples in

# 01.1 1-pass index
STAR --runMode genomeGenerate --runThreadN 8 --genomeDir 01.star_index/ \
--genomeFastaFiles $genome.fa --sjdbGTFfile $genome.gtf --sjdbOverhang 149

# 01.2 1-pass mapping with indexed genome
while read i ; do STAR --genomeDir 01.star_index/ --runThreadN 30 \ 
--readFilesIn $i'_1.cleaned.fq.gz'  $i'_2.cleaned.fq.gz'  --readFilesCommand zcat \
 --outSAMunmapped Within --outFileNamePrefix '02.1-pass/'$i  > '02.1-pass/log2map.'$i 2>&1  ; done < list

cat *.tab | awk '($5 > 0 && $7 > 2 && $6==0)' | cut -f1-6 | sort | uniq > SJ.filtered.tab
# 01.3 2-pass mapping with SJ.out.tab files
while read i; do STAR  --genomeDir 01.star_index/ --runThreadN 30 --sjdbFileChrStartEnd SJ.filtered.tab \
--readFilesIn $i'_1.cleaned.fq.gz'  $i'_2.cleaned.fq.gz'  --readFilesCommand zcat \
--outSAMmapqUnique 255 --outSAMtype BAM SortedByCoordinate --outBAMsortingThreadN 30 \
--outFileNamePrefix '03.2-pass/'$i \ > '03.2-pass/log2map.'$i 2>&1 ; done < list

while read i; do samtools index $i'Aligned.sortedByCoord.out.bam'; done < list
while read i; do samtools view -@ 10 -b -h -f 2 -q 255 $i'Aligned.sortedByCoord.out.bam' > '../04.gatk/'$i'.uniq.bam'; done < list

### 02 call variants using GATK4
# 02.1 GATK4: add RG, mark duplicates, and SplitNCigarReads
while read i; do  gatk AddOrReplaceReadGroups --INPUT $i'.uniq.bam'  --OUTPUT '01.rg/'$i'.RG.bam' --RGID $i --RGPL ILLUMINA --RGLB $i --RGPU RG --RGSM $i --CREATE_INDEX true; done < list1

while read i ; do gatk --java-options "-XX:ParallelGCThreads=20" MarkDuplicates \
-CREATE_INDEX true -VALIDATION_STRINGENCY SILENT --READ_NAME_REGEX null \
-I '01.rg/'$i'.RG.bam' -M '02.MarkDuplicates/'$i'.markdup_metrics.txt' -O '02.MarkDuplicates/'$i'.RG.markdup.bam'; done < list1

while read i ; do gatk --java-options "-XX:ParallelGCThreads=20" SplitNCigarReads --R $genome.fa \
--I '02.MarkDuplicates/'$i'.RG.markdup.bam' --O '03.SplitNCigarReads/'$i'.RG.markdup.split.bam' ; done < list

# 02.2 HaplotypeCaller
# the parameter reference source 1: https://gatk.broadinstitute.org/hc/en-us/articles/360035531192-RNAseq-short-variant-discovery-SNPs-Indels-
# the parameter reference source 2: https://github.com/gatk-workflows/gatk3-4-rnaseq-germline-snps-indels/blob/master/rna-germline-variant-calling.wdl

while read i; do 
gatk --java-options "-Xmx800m -Djava.io.tmpdir=./tmp" HaplotypeCaller  \
-R $REF -stand-call-conf 20 -dont-use-soft-clipped-bases \
-I '03.SplitNCigarReads/'$i'.RG.markdup.split.bam' \
-O '04.split.gvcf/'$i'.g.vcf.gz' \
-ERC GVCF ; done < list

# 02.3 merge the g.vcf files from same individual and GenotypeGVCFs
gatk --java-options "-Xmx12g"  CombineGVCFs  -R $REF --variant TA1.g.vcf.gz --variant TD1.g.vcf.gz --variant TG1.g.vcf.gz --variant TL1.g.vcf.gz --variant TM1.g.vcf.gz -O ../06.ind.gvcf/T1.g.vcf.gz
gatk --java-options "-Xmx12g"  GenotypeGVCFs -R $REF --variant T1.g.vcf.gz  -O T1.vcf.gz

# 02.4 SelectVariants (filter SNP) SNP and filter
gatk SelectVariants -select-type SNP  --restrict-alleles-to BIALLELIC -V T1.vcf.gz -O T1.snp.vcf.gz

gatk VariantFiltration --filter-name "FS"  --filter "FS > 30.0" --filter-name "QD"  --filter "QD < 2.0"  -V T1.snp.vcf.gz -O T1.snps_fld.vcf.gz
gatk SelectVariants --exclude-filtered TRUE -V T1.snps_fld.vcf.gz -O T1.snps_fld_sel.vcf.gz

zcat T1.snps_fld_sel.vcf.gz | SnpSift filter "( GEN[*].DP >= 10 )" > T1.snps.vcf
gatk SelectVariants --exclude-filtered TRUE -select "AN > 4" -V T1.snps.vcf -O T3.snps_fld_sel_2.vcf.gz
gatk SelectVariants -select "AF<1.00" --exclude-filtered TRUE -V T1.snps_fld_sel_2.vcf.gz  -O T1.snp2mask.vcf.gz

### 03 make individual genome
gatk FastaAlternateReferenceMaker -R $REF --line-width 80 \
-V T1.snps_fld_sel_2.vcf.gz --snp-mask T1.snp2mask.vcf.gz --snp-mask-priority -O T1.genome.fa

awk -F "[ :]" '{if($1~">")print ">"$2 ; else print$0}' T1.genome.fa > tmp && mv tmp T1.genome.fa
gatk CreateSequenceDictionary -R T1.genome.fa -O T1.genome.dict
samtools faidx T1.genome.fa

### 04 reads_mapping and make the bam files for read count
# 04.1 map reads
STAR --runMode genomeGenerate --runThreadN 20  --genomeDir 01.index/index_T1 --genomeFastaFiles ../04.gatk/08.ind.genome/T1.genome.fa --sjdbGTFfile ../CskiameaA.gtf --sjdbOverhang 149

while read i ; do STAR --genomeDir 01.index/index_T1 --runThreadN 20 \
--readFilesIn '../../00.cleaned.data/'$i'_1.cleaned.fq.gz'  '../../00.cleaned.data/'$i'_2.cleaned.fq.gz'  \
--readFilesCommand zcat --outSAMunmapped Within --outFileNamePrefix '02.1-pass/'$i  > '02.1-pass/log2map.'$i 2>&1  ; done < list1

cat T1*.tab | awk '($5 > 0 && $7 > 2 && $6==0)' | cut -f1-6 | sort | uniq > SJ.T1.filtered.tab

STAR --genomeDir ../01.index/index_T1 --sjdbFileChrStartEnd SJ.T1.filtered.tab --runThreadN 20 \
--readFilesIn '../../00.cleaned.data/'$i'_1.cleaned.fq.gz'  '../../00.cleaned.data/'$i'_2.cleaned.fq.gz' \
--readFilesCommand zcat --outSAMmapqUnique 255 --outSAMtype BAM SortedByCoordinate --outBAMsortingThreadN 30 --outFileNamePrefix $i; done < list1

# 04.2 deal the bam
while read i; do samtools index $i'Aligned.sortedByCoord.out.bam' ; done < list1
while read i; do samtools view -@ 10 -b -h -f 2 -q 255 $i'Aligned.sortedByCoord.out.bam' > $i'.uniq.bam'; done < list1

while read i ; do gatk --java-options "-XX:ParallelGCThreads=20" MarkDuplicates \
-CREATE_INDEX true -VALIDATION_STRINGENCY SILENT --READ_NAME_REGEX null \
-I $i'.uniq.bam' -M $i'.markdup_metrics.txt' -O $i'.RG.markdup.bam'; done < list1

while read i; do 
gatk --java-options "-XX:ParallelGCThreads=10" SplitNCigarReads --R T1.genome.fa \
--I $i'.RG.markdup.bam' --O $i'.markdup.pk.split.bam' > 'log2split.'$i 2>&1 ; done < list1


@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
## Make het-snp data for allele identify
## High-quality heterozygous SNPs are defined as those showing the same genotype in at least two tissue types,
## and if the hetSNP is only identified in one tissue, they are retained upon validation by DNA sequencing data

bcftools query -f '%CHROM\t%POS\t%ID\t%REF\t%ALT[\t%GT\t%DP]\n' T1.snps_fld_sel.vcf.gz > T1.output.txt
awk -v OFS='\t' '{for (i=7; i<=NF; i+=2) {if ($i < 20) $(i-1)="./."}}1' T1.output.txt > tmp
awk -v OFS='\t' '{for (i=6; i<=NF; i+=2) {if ($(i) == "0/1" || $(i) == "0|1") {print $0; break}}}' tmp > tmp1
awk  -v OFS='\t' '{count=0; for (i=6; i<=NF; i+=2) {count += gsub(/0\/1|0\|1/, "", $i)}; print $0"\t"count}' tmp1 > tmp2
awk -F "\t" '{if($16>1) print $0}' tmp2 | awk '{print $1"\t"$2}' > tmp3
awk -F "\t" '{if($16<2) print $0}' tmp2 | cut -f 1-5 > tmp4

gatk SelectVariants -V T1.DNA.filtered.snp.vcf.gz -select "AF < 1.00 " --exclude-filtered TRUE -O T1.DNA.het.filtered.snp.vcf.gz
zcat T1.DNA.het.filtered.snp.vcf.gz | grep -v "#" | cut -f 1-5 > T1.het.vcf
grep -Ff tmp4 -w T1.het.vcf | awk '{print $1"\t"$2}' > tmp4.site
cat tmp4.site tmp3 | sort -k 1,1 -k 2,2n > sites_to_keep.t1.txt

vcftools --gzvcf T1.snps_fld_sel.vcf.gz --positions sites_to_keep.t1.txt --recode --out T1.snp2ase

## adjust the file format

awk '{if(!/^#/) print $1"\t"$2"\t"$3"\t"$5"\t"$4"\t"$6"\t"$7"\t"$8"\t"$9"\t"$10}' T1.snp2ase.recode.vcf > T1.info.snp
grep "#" T1.snp2ase.recode.vcf > head.T1.list
cat  head.T1.list T1.info.snp | cut -f 1-10 > T1.info.snp.vcf

**manipulate_vcf.pl in the script**
./manipulate_vcf.pl -i T1.info.snp.vcf -o T1.info.snp.het.vcf
bcftools view -O z T1.info.snp.het.vcf > T1.info.snp.het.vcf.gz
bcftools index -t T1.info.snp.het.vcf.gz


## allele expression identify
awk '($3=="exon") {OFS="\t"; print $1,$4-1,$5}' /public1/node3_liushk/braker_result/03.braker_result/CskiameaA.longest.gff > CskiameaA_gff_exon.bed
vcftools --gzvcf T1.info.snp.het.vcf.gz --bed CskiameaA_gff_exon.bed --recode --out T1.het.snp.exon
bcftools view -O z T1.het.snp.exon.recode.vcf > T1.het.exon.vcf.gz
bcftools index -t T1.het.exon.vcf.gz


@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
allele identified using phaser
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
awk '$3=="gene"' CskiameaA.gff  | cut -f1,4,5,9 | awk -F $'\t' 'BEGIN {OFS = FS} {split($4, a, ";"); split(a[1], b, "="); print $1, $2-1, $3, b[2]}' > 01.csiA.gene.bed

cut -f 1 01.csiA.gene.bed | sort | uniq > 01.list
while read i ; do awk '{if($1=="'$i'")print $0}' 01.csiA.gene.bed > '02.'$i'.bed' ; done < 01.list

while read i ; do python /public/home/shicy/phaser/phaser/phaser.py --vcf T1.het.exon.vcf.gz \
--bam TA1.mk.split.bam,TD1.mk.split.bam,TG1.mk.split.bam,TL1.mk.split.bam,TM1.mk.split.bam  \
--paired_end 1 --mapq 60 --baseq 10 --sample TA5 --chr $i --threads 2  --id_separator - --o '02.phase/T1_'$i ; done < 01.bed/01.list

while read i; do python ~/phaser/phaser_gene_ae/phaser_gene_ae.py --haplotypic_counts 'T1_'$i'.haplotypic_counts.txt' \
--features '01.bed/02.'$i'.bed' --id_separator - --o '../09.phase_gene/T1_'$i'.gene_ae.txt'; done < 01.bed/list

### split the result to each tissue
cat T1_* > T1.tmp
grep TD1.mk.split 00.data/T1.tmp > TD1.tmp.txt && cat T1.head TD1.tmp.txt > T1.TD.filted.txt
grep TM1.mk.split 00.data/T1.tmp > TM1.tmp.txt && cat T1.head TM1.tmp.txt > T1.TM.filted.txt
grep TL1.mk.split 00.data/T1.tmp > TL1.tmp.txt && cat T1.head TL1.tmp.txt > T1.TL.filted.txt
grep TG1.mk.split 00.data/T1.tmp > TL1.tmp.txt && cat T1.head TL1.tmp.txt > T1.TG.filted.txt
grep TA1.mk.split 00.data/T1.tmp > TA1.tmp.txt && cat T1.head TA1.tmp.txt > T1.TA.filted.txt

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
### ASE test in R
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
######### ASE gene
### (sample$aCount>10 | sample$bCount>10) & sample$n_variants>2, binom_q<0.05
######### AE gene
### (sample$aCount>10 | sample$bCount>10) & sample$n_variants>2, binom_q>0.1

library(ggplot2)
read.table('T1.TA.filted.txt',sep = "\t",header = 1) -> sample
cov10 = subset(sample, (sample$aCount>10 | sample$bCount>10) & sample$n_variants>2 )
cov10$ase <- (log2(cov10$aCount+1)-log2(cov10$bCount+1))
cov10$binom_p <- apply(cov10[,c("aCount","bCount")], 1, function(x) binom.test(x[1],x[1]+x[2],p=0.5)$p.value)
cov10$binom_q <- p.adjust(cov10$binom_p, method = "fdr")
dense = data.frame(density(cov10$ase)[c('x','y')])

T1.TA_ASE <- cov10[cov10$binom_q<0.05,]
T1.TA_mark_gene<-cov10[,c(1:4)]
T1.TA_AE <- cov10[cov10$binom_q>0.1,c(1:4)]

P <- ggplot(cov10,aes(x =cov10$ase))+
    geom_histogram(aes(y=after_stat(density)), color="#3e403f", alpha=.1, fill="#fffbf0", binwidth = .12, center=1)+
    geom_density()+
    geom_area(data = subset(dense,x >= 1 & x < 10), aes(x, y, fill = "Label 1"), alpha=.5)+
    geom_area(data = subset(dense,x >= -10 & x < -1), aes(x, y, fill = "Label 2"), alpha=.5)+
    geom_area(data = subset(dense,x  >= -1 & x < 1), aes(x, y, fill = "Label 3"), alpha=.5)+
    scale_fill_manual("Label title",
                      breaks = c("Label 1", "Label 2", "Label 3"),
                      values = c("Label 1"="#de1300", "Label 2"="#027bc2", "Label 3"="#f2f2f2"))+
    labs(x = 'log2(aCount+1)-log2(bCount+1)')+
    theme_bw()+ theme(legend.title=element_blank(),legend.position = "none") +
    theme(axis.text = element_text(size=12),
          axis.title = element_text(size=14, face="bold"))

pdf("01.bais_T1A.pdf.pdf",width=6, height=3)
P
dev.off()

write.csv(T1.TA_mark_gene,'02.T1.TA_mark_gene.csv',row.names = F)
write.csv(T1.TA_AE,'03.T1.TA_AE.csv',row.names = F)
write.csv(T1.TA_ASE,'04.T1.TA_ASE.csv',row.names = F)
